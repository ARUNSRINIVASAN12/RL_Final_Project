{
 "cells": [
  {
   "cell_type": "code",
   "metadata": {
    "id": "Wd_oI57qabgR"
   },
   "source": [
    "!pip install gym[atari]\n",
    "!pip install autorom[accept-rom-license]\n",
    "!pip install highway-env"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "eJlDlCJaagMC",
    "outputId": "f0daef77-fc12-44e3-a21a-17e3d189bfd7"
   },
   "source": [
    "import highway_env\n",
    "import gymnasium as gym\n",
    "import sys\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import random\n",
    "from collections import namedtuple\n",
    "import numpy as np\n",
    "from collections import deque\n",
    "from torch.autograd import Variable\n",
    "import torch.nn.functional as F\n",
    "import tqdm\n",
    "import os\n",
    "import cv2\n",
    "import torch.distributions as distributions\n",
    "from torch.distributions import Normal\n",
    "from torch.distributions import MultivariateNormal\n",
    "from torch.distributions import Categorical"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "G4cFp93Qai8I",
    "outputId": "f71c3ed1-9d62-4223-8bea-cf72e22a4b5a"
   },
   "source": [
    "env = gym.make(\"parking-v0\", render_mode=\"rgb_array\")\n",
    "# env.unwrapped.config['add_walls']=False\n",
    "env.unwrapped.config['duration']=40\n",
    "obs,_=env.reset(seed=0)\n",
    "goal=obs['desired_goal'] #x,y,vx,vy,cos h ,sin h\n",
    "print(goal)\n",
    "env.close()\n",
    "env = gym.make(\"parking-v0\", render_mode=\"rgb_array\")\n",
    "# env.unwrapped.config['add_walls']=False\n",
    "env.unwrapped.config['duration']=20\n",
    "delta_x=0.03\n",
    "delta_y=0.03"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "tSE_EXju_L4a"
   },
   "source": [
    "def get_q_value(feature,weights,state, action):\n",
    "        features = feature(state)\n",
    "        w_a=weights[action]\n",
    "        q_value = np.dot(w_a, features.T)\n",
    "        return q_value"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "JIcGbZE5_1n-"
   },
   "source": [
    "def arg_max(lst):\n",
    "    max_val = max(lst)\n",
    "    max_indices = [i for i, x in enumerate(lst) if x == max_val]\n",
    "    return random.choice(max_indices)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "rSIhBVLM_diC"
   },
   "source": [
    "def car_e_greedy(feature,state,weights,epsilon):\n",
    "    probability= np.random.random()\n",
    "    if probability<=epsilon:\n",
    "        action=np.random.choice(num_of_actions)\n",
    "    else:\n",
    "        q_values=[]\n",
    "        for a in range(num_of_actions):\n",
    "            q_values.append(get_q_value(feature,weights,state,a))\n",
    "        action= arg_max(q_values)\n",
    "    return action"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "9qBwn3ZMH4vL"
   },
   "source": [
    "min_values = np.array([-1.5, -0.75])\n",
    "max_values = np.array([4.5, 2.25])\n",
    "\n",
    "# Define the number of bins for each dimension\n",
    "num_bins = np.array([500, 500])\n",
    "\n",
    "# Compute the bin widths for each dimension\n",
    "bin_widths = (max_values - min_values) / num_bins\n",
    "# print(bin_widths)\n",
    "def discretize_state(state):\n",
    "\n",
    "    # Map each dimension to its corresponding bin\n",
    "    discrete_state = ((state - min_values) / bin_widths).astype(int)\n",
    "    # Ensure the state falls within the valid range\n",
    "    discrete_state = np.clip(discrete_state, 0, num_bins - 1)\n",
    "    return tuple(discrete_state)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "EzgGTwqzzqWi"
   },
   "source": [
    "def feature_x(state):\n",
    "   state=discretize_state(state)\n",
    "   row,col=state[0],state[1]\n",
    "   num_cols=500\n",
    "   idx=row * num_cols + col\n",
    "   features=np.zeros((num_cols*num_cols))\n",
    "   features[idx]=1\n",
    "   return features"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "lHHNjfv8D0h3"
   },
   "source": [
    "def stepper(current_speeds,action):\n",
    "  if action==0:\n",
    "    current_speeds += np.array([0.2 ,0.0])\n",
    "  elif action==1:\n",
    "    current_speeds += np.array([-0.2, 0.0])\n",
    "  elif action==2:\n",
    "    current_speeds += np.array([0.0, 0.2])\n",
    "  elif action==3:\n",
    "    current_speeds += np.array([0.0, -0.2])\n",
    "  current_speeds=np.clip(current_speeds, -1.0, 1.0)\n",
    "  return np.array(current_speeds)\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Ie8aDibM8Rht",
    "outputId": "180d5e47-c237-4c1b-d361-1e3025910840"
   },
   "source": [
    "max_iter=5000\n",
    "alpha=0.1\n",
    "gamma=0.99\n",
    "feature=feature_x\n",
    "actions=np.array([0,1,2,3])\n",
    "epsilon=0.99\n",
    "num_of_actions=actions.shape[0]\n",
    "w=np.zeros((num_of_actions,500*500))\n",
    "goal_x,goal_y=goal[0:2]\n",
    "e_t=[]\n",
    "time_step=0\n",
    "rewards_list=[]\n",
    "rendered_frames=[]\n",
    "lengths_list=[]\n",
    "\n",
    "pbar=tqdm.trange(max_iter)\n",
    "for episode in pbar:\n",
    "  current_speeds=np.array([0.0 ,0.0])\n",
    "  state,_=env.reset(seed=0)\n",
    "  s=state['observation'][0:2]\n",
    "\n",
    "  s=discretize_state(s)\n",
    "  time_step +=1\n",
    "  a=car_e_greedy(feature,s,w,epsilon)\n",
    "  t=0\n",
    "  current_ep_reward=0\n",
    "  while(True):\n",
    "      current_speeds= stepper(current_speeds,a)\n",
    "      s_prime,r,done,truncated,info=env.step(current_speeds)\n",
    "      s_prime=s_prime['observation'][0:2]\n",
    "\n",
    "      s_prime=discretize_state(s_prime)\n",
    "      current_ep_reward +=r\n",
    "      time_step +=1\n",
    "\n",
    "      if time_step % 200==0:\n",
    "            epsilon =max(0.01, epsilon-0.001)\n",
    "\n",
    "      if info['is_success'] and done:\n",
    "        print(\"\\n Episode Complete \\n \")\n",
    "\n",
    "      if done or truncated:\n",
    "          if info['is_success']:\n",
    "            r+= 25\n",
    "          w[a]+= alpha*(r - get_q_value(feature,w,s,a))*feature(s)\n",
    "          e_t.append((episode,t))\n",
    "          pbar.set_description(\n",
    "                f'Episode: {episode} | Steps: {t + 1} | Return: {current_ep_reward:5.2f} |Epsilon: {epsilon}  '\n",
    "      )\n",
    "          rewards_list.append(current_ep_reward)\n",
    "          lengths_list.append((t+1))\n",
    "          break\n",
    "\n",
    "\n",
    "      else:\n",
    "\n",
    "          a_prime=car_e_greedy(feature,s_prime,w,epsilon)\n",
    "          w[a]+=alpha*(r+gamma*get_q_value(feature,w,s_prime,a_prime)-get_q_value(feature,w,s,a))*feature(s)\n",
    "          s=s_prime\n",
    "          a=a_prime\n",
    "          t+=1\n",
    "\n",
    "      if episode%499==0:\n",
    "        rendered_frames.append(env.render())\n",
    "\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "1qY6oikQ1e8f"
   },
   "source": [
    "def moving_average(data, *, window_size = 50):\n",
    "    \"\"\"Smooths 1-D data array using a moving average.\n",
    "\n",
    "    Args:\n",
    "        data: 1-D numpy.array\n",
    "        window_size: Size of the smoothing window\n",
    "\n",
    "    Returns:\n",
    "        smooth_data: A 1-d numpy.array with the same size as data\n",
    "    \"\"\"\n",
    "    # assert data.ndim == 1\n",
    "    kernel = np.ones(window_size)\n",
    "    smooth_data = np.convolve(data, kernel) / np.convolve(\n",
    "        np.ones_like(data), kernel\n",
    "    )\n",
    "    return smooth_data[: -window_size + 1]"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "Unyf0pJ81jsP",
    "outputId": "6f6687b2-e939-422b-f91e-f48eb90f349b"
   },
   "source": [
    "# YOUR PLOTTING CODE HERE\n",
    "plt.figure(figsize=(10, 6))\n",
    "# plt.subplot(3, 1, 1)\n",
    "plt.plot(rewards_list, label='Returns (Raw Data)', alpha=0.5)\n",
    "plt.plot(moving_average(rewards_list), label='Returns (Moving Average)', color='orange')\n",
    "plt.title('Returns')\n",
    "plt.xlabel('Episode')\n",
    "plt.ylabel('Return')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "plt.close()\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(lengths_list, label='Lengths (Raw Data)', alpha=0.5)\n",
    "plt.plot(moving_average(lengths_list), label='Lengths (Moving Average)', color='orange')\n",
    "plt.title('Lengths')\n",
    "plt.xlabel('Episode')\n",
    "plt.ylabel('Length')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "plt.close()\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(PPO_losses, label='Losses (Raw Data)')\n",
    "plt.plot(moving_average(PPO_losses), label='Losses (Moving Average)', color='orange')\n",
    "plt.title('Losses')\n",
    "plt.xlabel('Batch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
